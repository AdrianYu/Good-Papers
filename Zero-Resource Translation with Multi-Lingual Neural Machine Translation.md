- Zero-Resource Translation with Multi-Lingual Neural Machine Translation - https://arxiv.org/pdf/1606.04164.pdf

This paper investigates how to apply multi-lingual neural machine translation to zero-resource translation. Both the topics are pretty 
cool. Multi-lingual NMT translate between multiple languages using single shared attention mechanism (http://www.aclweb.org/anthology/N16-1101) (See this
for a review https://github.com/hoangcuong2011/Good-Papers/blob/master/Multi-way%2C%20Multilingual%20neural%20machine%20translation%20with%20a%20shared%20attention%20mechanism.md).
Zero-resource translation concerns with the case where there does not exist any direct parallel examples between a source-target language pair. 
In the context of SMT, zero-resource translation has been addressed by pivot-based translation, but the performance is not that
great.
